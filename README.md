# Question answering with the Transformers (HuggingFace) library and Gradio webapp

In this repo, we use HuggingFace transformers library for Question Answering. 

**Libraries and installations**

The libraries that are used in this repo are reported in the "environment.yml" file.

To install the libraries, execute the following command in Anaconda Prompt:

conda env create -f environment.yml

After the libraries are installed, execute in Anaconda Prompt:

conda activate qna_app_env

python -m ipykernel install --user --name=qna_app_env

The latter command is used to install the environment as a kernel in Jupyter notebooks.

**Question answering with the transformers library and the Gradio webapp**

The code for question answering and the code for the Gradio app is reported in the repo's jupyter notebook.
